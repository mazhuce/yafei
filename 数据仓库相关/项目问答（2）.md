### ✅ 1. 为什么要做这个平台？解决了什么问题？

> “背景是企业内部有多个业务团队需要用机器学习模型，但没有统一的工具链，模型开发、部署、调用都很分散。  
> 我们搭建了一个 MaaS 平台，业务团队可以像使用云服务一样上传数据、训练模型、管理实验、发布API。解决了模型生命周期管理、训练流程规范化、部署上线慢的问题。”
### ✅ 2. 技术架构大图

可以这样解释：

> “整个架构分四层：> 
> - **前端**：Vue.js + Element UI，负责模型管理的可视化。>     
> - **后端**：Spring Boot，提供统一 RESTful API，驱动整个流程。>     
> - **训练调度**：Spark MLlib 负责分布式训练，Airflow 调度任务。>     
> - **部署/服务**：Docker、Kubernetes，实现模型容器化部署并暴露API。>     
> - **模型管理**：MLflow 记录实验、版本；Redis 缓存状态。”
### ✅ 3. Spring Boot 的角色

> “后端是整个系统的大脑，用 Spring Boot 搭建，职责是：> 
> - 提供统一的RESTful API>     
> - 管理用户请求：上传模型文件、配置参数、启动训练、发布服务>     
> - 调用 Airflow API 触发训练 DAG>     
> - 查询 MLflow 记录>     
> - 生成 Kubernetes 部署YAML或调用K8s API>     
> - 管理状态缓存（通过 Redis）>  
> 设计成分层架构：Controller层做API暴露，Service层封装业务逻辑，DAO层持久化模型元信息。”
### ✅ 4. Vue.js + Element UI

> “前端做了一个可视化管理界面：> 
> - 模型上传（支持文件/版本信息填写）>     
> - 训练参数配置>     
> - 训练任务列表与状态跟踪>     
> - 实验记录查看（集成MLflow UI 或简化版表格）>     
> - 部署发布按钮>     
> - 技术上是Vue 3 + Element UI，组件化开发，前后端分离，通过Spring Boot API交互。”
### ✅ 5. Spark MLlib + Airflow

> “后端训练用 Spark MLlib 实现分布式算法支持（回归、分类等）。> 
> 设计模式是：> 
> - Spring Boot 接到训练请求后写入参数和配置>     
> - 调用 Airflow REST API，触发特定 DAG>     
> - Airflow DAG在集群里启动 Spark 作业>     
> - Spark 读HDFS/对象存储里的数据，训练模型>     
> - 训练结果（模型文件、指标）上传到对象存储/注册到MLflow>     > 
> Airflow 的好处是可视化调度、任务依赖管理、失败重试。”
### ✅ 6. MLflow

> “MLflow主要用于模型生命周期管理：> 
> - 记录实验（参数、指标、模型文件）>     
> - 管理模型版本>     
> - 提供查询API给后端>     
> 我们的后端会把训练结果注册到 MLflow，并查询版本信息用于发布部署。”
### ✅ 7. Docker + Kubernetes

> “模型部署这块是平台的一大亮点：> 
> - 每个模型服务打包成Docker镜像>     
> - 平台里配置了镜像仓库>     
> - Spring Boot在接到发布请求时，调用Kubernetes API>     
> - 自动拉取镜像，创建 Deployment 和 Service>     
> - 暴露RESTful API接口>     
> 实现了一键部署、自动伸缩、版本升级回滚。”
### ✅ 8. Redis 的作用

> “用Redis做了几件事：> 
> - 缓存用户会话/权限信息>     
> - 存储任务状态（比如Airflow任务ID与我们平台任务ID的映射）>     
> - 部分临时查询结果缓存，减轻数据库压力。”
#### **Q: 为什么选择 Spring Boot 作为后端框架？**

- **生态系统与整合能力**：Spring Boot 是 Java 生态的事实标准，拥有强大的社区支持。它可以非常轻松地与各种中间件（Redis, Kafka）、数据库、以及外部 API (如 Airflow, Kubernetes, MLflow) 进行整合。    
- **工程化与稳定性**：对于一个平台型项目，需要考虑服务的稳定性、安全性、可维护性。Spring Boot 在这些方面有非常成熟的解决方案，比用 Python 脚本搭建的后端更具工程化的优势。    
- **API 驱动**：项目描述强调“API 驱动整个生命周期”，Spring Boot 构建 RESTful API 非常高效和规范，是这种模式的理想选择。    

#### **Q: MLflow 在这个平台中解决了哪些痛点？**

- **解决了“实验混乱”的痛点**：算法工程师通常会做大量实验，如果没有 MLflow，参数、代码版本、数据集和结果之间的对应关系会变得一团糟。MLflow Tracking 提供了标准化的实验记录，让一切**可追溯、可复现**。    
- **解决了“模型交付”的痛点**：在没有 Model Registry 之前，模型交付可能是通过发邮件、共享文件夹等原始方式。**MLflow Model Registry** 提供了一个中央化的、有版本控制的“模型商店”，清晰地管理了模型的生命周期（`Staging`, `Production`, `Archived`），为自动化部署提供了“单一可信源”。    
- **解耦**: MLflow 将模型训练过程与模型的使用过程解耦，是一个连接开发与部署的“标准接口”。    

#### **Q: 为什么用 Kubernetes (K8s) 来部署模型？它带来了什么好处？**

- **资源隔离与弹性伸缩**：每个模型服务都运行在独立的 Docker 容器中，互不影响。K8s 可以根据访问负载自动增加或减少模型服务的实例数量（Pod数量），高效利用资源。    
- **高可用与自愈能力**：如果某个模型实例崩溃了，K8s 的 `Deployment` 会自动重新创建一个新的实例来替代它，保证了模型服务的稳定性。K8s 的 `Service` 提供了一个稳定的访问入口，屏蔽了后端实例的变化。    
- **标准化部署**：无论模型是用 TensorFlow, PyTorch, 还是 Scikit-learn 写的，只要能打包成一个标准的 Docker 镜像，K8s 就能以同样的方式部署和管理它，极大地简化了运维。**实现了真正的“一次构建，到处运行”**。    

#### **Q: Spark MLlib 在这个架构中的角色和必要性？**

- **处理大规模数据**：当训练数据量大到单机内存无法容纳时，就必须使用分布式计算框架。Spark MLlib 可以在集群上并行处理数据和训练模型，是解决大数据场景下机器学习问题的标准工具。    
- **作为后端训练引擎**：平台本身不负责具体的计算，而是将计算任务“外包”给强大的分布式引擎。Spark 在这里就是被集成的那个“引擎”，平台负责给它下发任务和回收结果。
#### **场景题 1：“一键部署”的背后，你的 Spring Boot 服务具体做了哪几件关键事情？”**

**回答思路：** 清晰地描述出自动化流程的每一步，展现你的实现能力。
“当用户点击部署后，后端的 Spring Boot 服务会启动一个预设的部署流水线，主要包含以下几个原子操作：
1. **模型拉取**：调用 MLflow 的 Java Client，根据传入的模型ID和版本，从 Model Registry 下载模型文件压缩包到一个临时工作目录。    
2. **镜像构建**：我们会有一个标准的模型服务项目模板，包含 `Dockerfile` 和一个轻量级的 Web Server。后端服务会将下载的模型文件解压到这个模板的指定位置，然后调用 Docker 的 API 或命令行工具执行 `docker build`，生成一个带版本号的镜像。    
3. **镜像推送**：将构建好的镜像 `docker push` 到我们私有的Harbor镜像仓库。    
4. **K8s 部署**：使用 Kubernetes 的 Java Client（如 Fabric8），加载预先定义好的 `Deployment` 和 `Service` YAML 模板。我们会用刚刚构建的镜像地址和用户指定的资源配置（如CPU/内存请求）填充模板，然后向 K8s API Server 发送创建或更新请求。    
5. **状态反馈**：后端会轮询 K8s API，监控 Deployment 的状态，直到新的 Pod 成功运行，然后将生成的 Service 访问地址返回给前端。”    

#### **场景题 2：“如果一个已上线的模型出现性能衰退（Model Drift），你的平台如何支持模型的更新和回滚？”**

**回答思路：** 结合 MLflow 和 K8s 的优势来回答，体现 MLOps 的闭环思想。
1. **模型更新 (A/B Test 或蓝绿部署)**：    
    - 首先，算法工程师会基于新数据重新训练一个更优的模型，并将其注册到 MLflow Model Registry，标记为新的 `Production` 版本（例如 `v2`）。        
    - 在部署时，我们的平台支持**蓝绿部署**策略。Spring Boot 服务不会直接替换掉旧的 `v1` 版本，而是会创建一个全新的 `Deployment` 来运行 `v2` 模型。        
    - 然后通过修改 K8s `Service` 的 `selector`，将流量平滑地从 `v1` 的 Pods 切换到 `v2` 的 Pods。这保证了更新过程服务不中断。如果需要 A/B 测试，可以利用更高级的服务网格（Service Mesh, 如 Istio）来做流量切分。        
2. **模型回滚**：    
    - 如果发现新上线的 `v2` 模型有问题，回滚操作非常迅速和安全。        
    - 我只需要在平台前端点击“回滚”按钮，后端就会立即执行一个反向操作：将 K8s `Service` 的流量切回给仍在运行的 `v1` 模型 `Deployment`。        
    - 同时，在 MLflow Model Registry 中，可以将 `v2` 的状态从 `Production` 降级为 `Archived`，将 `v1` 重新标记为 `Production`，保证了模型资产管理的一致性。**这整个过程因为 K8s 和 MLflow 的存在，可以在分钟级别内完成。**”