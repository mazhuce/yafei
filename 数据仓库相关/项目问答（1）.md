## ✅ 架构目标

- 湖仓一体：一个统一的 Iceberg 表层，支撑流批两种写入和查询    
- 实时 + 离线链路打通：支持分钟级入湖 + T+1 批处理    
- 统一元数据管理、分区管理、Schema 演进    
- 保证数据一致性和可追溯    
- 降低维护成本，提高开发效率   
## ✅ 设计原则

- 数据分层建模（ODS、DWD、DWS、ADS）    
- 流批同源：都落 Iceberg 表    
- 流写、批写共用 Schema    
- 低延迟：实时层 < 5分钟    
- 高可维护性：用 dbt 做模型编排和测试
#### **Q: 为什么选择 Iceberg 作为核心存储？它解决了什么问题？**

**回答策略：** 回答要突出 Iceberg 相对于传统 Hive 或直接操作文件（Parquet/ORC）的优势。
- **解决了“湖”的不可靠问题**：Iceberg 通过元数据快照（Snapshot）机制，为数据湖带来了 **ACID 事务**。Flink 实时写入时，即使任务失败，也不会产生“脏数据”或不完整的文件，保证了数据的一致性。    
- **实现了真正的“流批一体”**：Flink（流）和 Spark（批）可以安全地读写同一张 Iceberg 表，而不会互相干扰。Flink 的 `commit` 操作对 Spark 是原子可见的，解决了传统 Lambda 架构下数据不一致和双管道维护成本高的问题。    
- **简化了数据管理**：    
    - **模式演进 (Schema Evolution)**: 可以安全地增加、删除、重命名列，而不会破坏旧数据或影响正在运行的查询，这对于业务快速迭代的电商场景至关重要。        
    - **时间旅行 (Time Travel)**: 可以轻松查询到表的任意历史版本（快照），非常便于数据回滚、问题排查和审计。例如，“恢复到昨天任务运行前的状态”。      
    - **隐藏分区 (Hidden Partitioning)**: 分区信息由 Iceberg 管理，用户查询时无需在 `WHERE` 子句中指定分区字段，简化了查询，避免了因分区管理不当导致的性能问题。      
#### **Q: 为什么实时部分用 Flink，批量部分用 Spark？只用一个不行吗？**

**回答策略：** 突出“用合适的工具做合适的事”。
- **Flink 的优势在于流处理**：    
    - **低延迟和高吞吐**：Flink 是为真正的流计算而生，其事件驱动的架构和优秀的状态管理机制（Stateful Processing），能做到毫秒到秒级的延迟。`Flink CDC` 更是将延迟推向了极致。        
    - **精确一次 (Exactly-once) 语义**：Flink 的 Checkpoint 机制保证了端到端的数据处理不重不丢，对于金融级别的指标计算非常重要。
- **Spark 的优势在于批处理**：    
    - **强大的生态和成熟度**：Spark 在大规模批处理领域非常成熟，能很好地处理TB甚至PB级别的复杂ETL和聚合任务。        
    - **资源调度和容错**：它的容错机制和资源调度模型非常适合长时间运行的大型任务。对于 DWS/ADS 层这种需要关联多张大表、进行复杂窗口计算和聚合的场景，Spark 是更稳健、资源利用率更高的选择。        
- **总结**：虽然 Flink 也能做批处理（Flink Batch），Spark 也有流处理（Spark Streaming），但在业界，**Flink-Streaming + Spark-Batch** 是一个黄金组合，各自发挥其最擅长的领域，实现了性能和稳定性的最佳平衡。
#### **Q: dbt 在这个架构里扮演什么角色？它有什么价值？**

**回答策略：** 强调 dbt 带来的“软件工程最佳实践”。
- **它不是一个计算引擎，而是一个“转换(Transformation)编排和治理工具”**。它把数据分析师和工程师从繁琐的工作中解放出来。
- **核心价值**：    
    - **SQL as Code (SQL即代码)**: 将所有数据转换逻辑用 SQL 定义，并用 Git 进行版本控制，实现了协作和可追溯性。        
    - **自动化依赖管理**: 你只需要在模型中使用 `ref('another_model')`，dbt 就会自动分析并构建出正确的执行顺序（DAG图）。        
    - **数据质量保障**: 可以方便地编写测试用例（如 `not_null`, `unique`，或自定义SQL测试），并在每次运行时自动执行，确保数据质量。        
    - **文档自动化**: dbt 可以根据你的代码和描述自动生成数据模型的文档网站，极大地促进了“数据口径”的统一和知识共享。       
#### **Q: Trino 的作用是什么？为什么不用 Spark SQL 或 Flink SQL 来做即席查询？**

- **定位不同**: Trino 的设计目标就是 **高性能、低延迟的交互式查询**。它是一个纯粹的查询计算引擎。    
- **为什么不用 Spark/Flink SQL**:    
    - **Spark SQL**: 启动开销较大（Task 调度、资源申请），更适合批处理任务，对于分析师“问一个问题，等一分钟”的交互式场景，体验不佳。        
    - **Flink SQL**: 主要为流式查询设计，虽然也能查批表，但生态和性能优化上不如专门的 OLAP 引擎。        
- **Trino 的优势**:    
    - **MPP (大规模并行处理) 架构**: 专为快速查询优化，启动快，执行效率高。        
    - **解耦**: 它和数据源（Iceberg）完全解耦，可以一个 Trino 集群查询多个不同的数据源（Iceberg, Hive, MySQL, Kafka等），非常灵活。

#### **场景题 1：“如果线上业务库中一个核心表需要增加一个字段，你的数据流需要做什么调整？这个架构如何应对？”**

**回答思路：** 这是考察对 Iceberg Schema Evolution 理解的绝佳问题。
1. **源头**：业务库 `ALTER TABLE` 后，`Flink CDC` 会自动捕获到这个 DDL 变化。    
2. **实时链路**：Flink 的 Iceberg Sink 连接器可以感知到 Schema 的变化。你需要在 Flink 作业中配置好相应的策略，使其能够将新增列的数据平滑地写入 Iceberg 表的 ODS 层。Iceberg 本身支持 `add column` 操作，不会影响老数据。    
3. **下游处理**：    
    - **DWD 层**：如果 DWD 层需要用到这个新字段，你需要修改 Flink SQL 作业，将新字段加入计算逻辑并写入 DWD 表。同样，Iceberg 的 Schema Evolution 会保证这个过程的平滑。        
    - **DWS/ADS 层**：修改 dbt 中的 SQL 模型和 Spark 任务代码，将新字段纳入离线统计。由于 dbt 的存在，这个修改是有版本控制和可测试的。        
4. **总结优势**：整个流程中，**Iceberg 的 Schema Evolution 是关键**，它保证了整个数据链路无需停止，在线即可完成变更，极大地提升了敏捷性。    

#### **场景题 2：“某一天，你发现 ADS 层的一个核心报表数据是错误的，你会如何排查这个问题？”**

**回答思路：** 这考察你的问题排查能力和对架构端到端（End-to-End）的理解。
1. **利用时间旅行定位问题**：首先，我会利用 Iceberg 的 **时间旅行（Time Travel）** 功能，查询出 ADS 表在“出错前”和“出错后”的快照数据，精确对比，确定问题出现的具体时间和范围。    
2. **逆向链路排查**：    
    - **ADS -> DWS**: 检查生成该 ADS 表的 Spark 任务和 dbt 模型。查看 Airflow 上的任务日志，确认当时是否有执行失败、数据倾斜等问题。在 dbt 中检查相关的 SQL 逻辑是否有变更。        
    - **DWS -> DWD**: 如果 DWS 层的输入（DWD表）就有问题，继续向上追溯。同样，使用时间旅行查询 DWD 表在问题时间点的数据。        
    - **DWD -> ODS**: 检查实时 Flink 作业。查看 Flink 的 Checkpoint 历史和日志，确认是否有数据延迟、处理异常或反压等情况。        
    - **ODS -> Source**: 最终追溯到 ODS 层和源头。检查 Flink CDC 是否完整捕获了 `binlog`，或者 Kafka 中是否有数据积压或丢失。        
3. **数据恢复**：一旦定位到问题根源（比如是一个有 bug 的 Spark 任务导致的），修复代码后，可以利用 Iceberg 的时间旅行功能快速回滚到正确的版本，或者重新运行 Spark 任务覆盖错误数据，实现快速恢复。